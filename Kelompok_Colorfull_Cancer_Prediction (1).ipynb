{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Breast Cancer Prediction Menggunakan Binary Classification (Neural Network)"
      ],
      "metadata": {
        "id": "SYkjAZN5xgAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anggota :\n",
        "1.   Johana Paskalina Sihotang (Accuracy & Model Loss Plot , Testing Program)\n",
        "2.   Rodiatul Husna Br Sitepu (Data Wrangling, Data Validation & Model Creation)\n",
        "3.   A. Nurcahaya Tampubolon  (Data Cleansing, Data Training & Evaluation)\n",
        "4.   Yessica Angelita Situmorang (Import Library & Load Dataset)\n"
      ],
      "metadata": {
        "id": "AAwwE5OUlG4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "cUQQD-9PxkJk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjJxfnYFjb0R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # digunakan untuk manipulasi dan analisis data\n",
        "import numpy as np # digunakan untuk komputasi numerik dalam python\n",
        "import tensorflow as tf # digunakan untuk membangun, melatih dan menerapkan model pembelajaran mesin\n",
        "from tensorflow import keras # digunakan untuk membangun dan melatih model menggunakan jaringan neural networks\n",
        "from matplotlib import pyplot as plt # digunakan untuk plotting data\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "eSJo4oBFx4qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Download: [Breast_Cancer_Prediction.csv](https://github.com/johanasht/Prediksi-Kanker-Payudara/blob/main/breast_cancer_prediction.csv)"
      ],
      "metadata": {
        "id": "HoCiveEEC5o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfmXihURjvWA",
        "outputId": "52b7de88-c2e3-4425-cc55-622e526d06ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4451ff2b-3cb2-436e-9851-fc5b1fa777ba\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4451ff2b-3cb2-436e-9851-fc5b1fa777ba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# membaca data\n",
        "df = pd.read_csv('breast_cancer_prediction.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "QQDCzJLKku0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rs9Y2Od_lMTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# membaca data\n",
        "df.info()"
      ],
      "metadata": {
        "id": "YivkEk9jlMqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "Ss1YMRqjy6cp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling"
      ],
      "metadata": {
        "id": "jtFqf4z-dqEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# menampilkan kolom dataset\n",
        "df.columns"
      ],
      "metadata": {
        "id": "HA3hsxBrwN3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# memilih kolom yang diperlukan untuk proses pengujian\n",
        "df = df[['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']]"
      ],
      "metadata": {
        "id": "SzJJ1jjXwPGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# menampilkan kembali dataset yang sudah difilter kolomnya\n",
        "df"
      ],
      "metadata": {
        "id": "NXJqrw_QBReb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# menampikan isi dari kolom diagnosis\n",
        "df['diagnosis'].unique()"
      ],
      "metadata": {
        "id": "4hlXMq75mhnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disini **'M'** digunakan untuk menunjukkan status ***malignant*** yang artinya kanker tersebut bersifat ganas sedangkan **'B'** menunjukkan status ***benign*** yang artinya kanker tersebut bersifat jinak"
      ],
      "metadata": {
        "id": "pNgvnB-k9SwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleansing"
      ],
      "metadata": {
        "id": "Q3R8XUh7dwhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# melihat seluruh kolom beserta dengan type data nya, jumlah, unique values dan missing value nya\n",
        "# diurutkan secara descending berdasarkan missing values\n",
        "missing = []\n",
        "unique = []\n",
        "types = []\n",
        "variables = []\n",
        "count = []\n",
        "\n",
        "for item in df.columns:\n",
        "    variables.append(item)\n",
        "    missing.append(df[item].isnull().sum())\n",
        "    unique.append(df[item].nunique())\n",
        "    types.append(df[item].dtypes)\n",
        "    count.append(len(df[item]))\n",
        "\n",
        "output = pd.DataFrame({\n",
        "    'variable': variables,\n",
        "    'dtype': types,\n",
        "    'count': count,\n",
        "    'unique': unique,\n",
        "    'missing': missing,\n",
        "\n",
        "})\n",
        "output.sort_values(\"missing\",ascending=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "PnPsZht6mCL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cek apakah ada data yang duplikat\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "awjGUw5smKDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# menggunakan boxplot untuk melihat apakah ada outliers di tiap kolom dari dataset\n",
        "df.boxplot(column=list(df.select_dtypes(include=[np.number]).columns))\n",
        "plt.xticks(np.arange(1, len(df.columns) + 1), df.columns, rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x0FZfdJhd-Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# melihat persebaran data tiap kolom\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "GgrNwwdQ5QMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function untuk mengecek apakah terdapat outliers dalam data menggunakan IQR\n",
        "def outliers(df, feature):\n",
        "  q1 = df[feature].quantile(0.25)\n",
        "  q3 = df[feature].quantile(0.75)\n",
        "  iqr = q3 - q1\n",
        "\n",
        "  lower_bound = q1 - 1.5 * iqr\n",
        "  upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "  ls = df.index[ (df[feature] < lower_bound) | (df[feature] > upper_bound) ]\n",
        "\n",
        "  return ls"
      ],
      "metadata": {
        "id": "CjWKUCSlgVrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "8y2nb7dIgWFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# membuat sebuah list dengan nama index_list yang akan menampung index dari outliers dari semua feature yang terdapat pada data\n",
        "index_list = []\n",
        "for feature in ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']:\n",
        "               index_list.extend(outliers(df, feature))\n",
        "\n",
        "index_list"
      ],
      "metadata": {
        "id": "fFRjXa6jgaA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function untuk menghapus data yang termasuk outliers\n",
        "def remove(df, ls):\n",
        "  ls = sorted(set(ls))\n",
        "  df = df.drop(ls)\n",
        "  return df"
      ],
      "metadata": {
        "id": "yrpdIkMogaHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variable df_cleaned akan memanggil function remove dan menyimpan data yang outliers nya sudah dihapus\n",
        "df = remove(df, index_list)\n",
        "# mengecek jumlah baris dan kolom setelah outliers sudah dihapus\n",
        "df.shape"
      ],
      "metadata": {
        "id": "qpB3J95_gflZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Validation"
      ],
      "metadata": {
        "id": "KoQtfDqf6RUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kita gunakan replace untuk mengganti M menjadi 1 dan B menjadi 0 agar\n",
        "# nantinya dapat digunakan untuk proses binary classification\n",
        "df['diagnosis'].replace(['M', 'B'], [1, 0], inplace=True)"
      ],
      "metadata": {
        "id": "vaUbblPqmUIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# menampilkan info tipe data dan frekuensi tiap kolom\n",
        "df.info()"
      ],
      "metadata": {
        "id": "WuDuAWnqn_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "UPbuHoIroELE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# membuat variabel X yang akan menyimpan variabel independen dan variabel y\n",
        "# yang akan mwnyimpan variabel dependen\n",
        "X = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']]\n",
        "y = df['diagnosis']"
      ],
      "metadata": {
        "id": "WN-FHjxyoc0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation\n"
      ],
      "metadata": {
        "id": "R7ntzFKfjZQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing # menyediakan fungsi preprocessing data\n",
        "\n",
        "# melakukan penskalaan fitur dengan metode Min-Max Scaling. Metode ini\n",
        "# mengubah fitur-fitur menjadi rentang yang lebih kecil, yaitu dari 0 hingga 1.\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "metadata": {
        "id": "HwtfE__xo5pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# membagi dataset menjadi training set dan test set dimana\n",
        "# 70% data dipakai untuk training dan 30% untuk testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X_scale, y, test_size=0.3\n",
        ")"
      ],
      "metadata": {
        "id": "10SI6M3Jo7gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah tipe data variabel y_train dan y_test menjadi float\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)"
      ],
      "metadata": {
        "id": "VCjLUA4ypAq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Training"
      ],
      "metadata": {
        "id": "mce5oeBX6Bd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membangun model neural network yaitu binary classification\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "  Dense(1024, activation='relu', input_shape=[10]), # 10 input, 1024 neuron\n",
        "  Dense(1024, activation='relu'), # 1024 neuron\n",
        "  Dense(1, activation='sigmoid'), # 1 output\n",
        "])\n",
        "\n",
        "# Fungsi aktivasi sigmoid digunakan untuk masalah klasifikasi biner,\n",
        "# di mana output yang dihasilkan berada dalam rentang antara 0 dan 1"
      ],
      "metadata": {
        "id": "Xtd2sCFfpAt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Konfigurasi model\n",
        "model.compile(\n",
        "  optimizer='adam', # optimizer Adam digunakan untuk optimasi\n",
        "  loss='binary_crossentropy', # binary cross entropy untuk binary classification\n",
        "  metrics=['binary_accuracy'], # mengukur persentase jumlah prediksi benar terhadap total data\n",
        ")"
      ],
      "metadata": {
        "id": "HWSibgekpgnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model\n",
        "h = model.fit(X_train, y_train, epochs=30)"
      ],
      "metadata": {
        "id": "eDQ7J8k_piy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengevaluasi model yang sudah dibuat\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "29QT9_Kaq0m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari hasil evaluasi, didapatkan nilai akurasi sebesar 95,36% persen yang menunjukkan bahawa model memiliki tingkat akurasi yang cukup tinggi dan nilai loss sebesar 0.1797 yang rendah yang menandakan bahwa model yang dibuat ini mempunyai hasil yang baik."
      ],
      "metadata": {
        "id": "k4auiqR6EbiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan akurasi model dalam bentuk plot\n",
        "plt.plot(h.history['binary_accuracy'])\n",
        "plt.title('Model Accuracy Plot')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ztnTyacXrGgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan Plot : Dalam grafik diatas, akurasi model memiliki nilai [ 0.9536423683166504] pada Epoch ke 30 dari yang awalnya kurang dari (<) [0.775] pada Epoch 0. Ini menunjukkan bahwa model Anda memiliki akurasi sekitar 95.364 %, yang berarti model berhasil memprediksi dengan benar sekitar 95.364 % dari semua sampel yang dievaluasi.\n"
      ],
      "metadata": {
        "id": "yIEK_Nsu_dzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan model loss dalam bentuk plot\n",
        "plt.plot(h.history['loss'])\n",
        "plt.title('Model Loss Plot')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iukRZ1Z_r-la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan Plot : Dalam grafik diatas, model loss memiliki nilai [0.17974278330802917] pada Epoch ke 30 dari yang awalnya lebih dari (>) [0.5] pada Epoch 0. Nilai ini menunjukkan seberapa besar perbedaan antara prediksi model dengan nilai yang sebenarnya. Semakin rendah nilai loss, semakin baik performa model yang dibuat. Jadi, dalam contoh ini, model memiliki loss yang rendah, yang mengindikasikan bahwa prediksi model secara bertahap memperbaiki prediksinya seiring berjalannya pelatihan."
      ],
      "metadata": {
        "id": "GE0ECAXE_eqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Program\n"
      ],
      "metadata": {
        "id": "as5MyENwifWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data pengujian\n",
        "x_test = np.array([[17.99, 10.38, 122.80, 1001.0, 0.11840, 0.27760, 0.30010, 0.14710, 0.2419, 0.07871],\n",
        "                   [16.6, 12.7, 120.0, 1000.0, 0.1, 0.3, 0.3, 0.17, 0.2134, 0.063],\n",
        "                   [7.76, 24.54, 47.92, 181.0, 0.05263, 0.04362, 0.00000, 0.00000, 0.1587, 0.05884]])\n",
        "\n",
        "# Melakukan penskalaan pada data pengujian\n",
        "x_test_scaled = min_max_scaler.transform(x_test)\n",
        "\n",
        "# Melakukan prediksi menggunakan model\n",
        "predictions = model.predict(x_test_scaled)\n",
        "\n",
        "# Mengubah nilai prediksi menjadi label klasifikasi (M = Malignant (Ganas), B = Benign (Jinak))\n",
        "class_labels = ['B', 'M']\n",
        "\n",
        "# Menampilkan hasil prediksi\n",
        "for i in range(len(predictions)):\n",
        "    predicted_label = class_labels[int(np.round(predictions[i]))]\n",
        "    print(\"Hasil Prediksi {}:\".format(i+1), predicted_label)"
      ],
      "metadata": {
        "id": "3hvgwSfEoMqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n"
      ],
      "metadata": {
        "id": "enz4rhqS0HQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kesimpulan:\n",
        "\n",
        "Program breast cancer detection yang telah dibuat menggunakan binary classification (neural networks) mampu mencapai tingkat akurasi antara 94% hingga 96% dengan tingkat kehilangan (model loss) sebesar 9% hingga 18%. Hal ini menunjukkan bahwa program tersebut memiliki performa yang baik dalam mengklasifikasikan apakah pasien mengidap kanker payudara atau tidak.\n",
        "\n",
        "Dengan tingkat akurasi yang tinggi, yaitu antara 94% hingga 96%, program dapat memberikan prediksi yang akurat dalam mengidentifikasi pasien yang terkena kanker payudara. Tingkat akurasi ini menunjukkan bahwa sebagian besar pasien dengan kanker payudara dapat terdeteksi dengan benar oleh program.\n",
        "\n",
        "Selain itu, tingkat kehilangan (model loss) program yang berkisar antara 9% hingga 18% juga cukup rendah. Hal ini menunjukkan bahwa program memiliki kemampuan yang baik dalam meminimalkan kesalahan atau ketidakcocokan antara prediksi dan nilai sebenarnya.\n",
        "\n",
        "Dengan tingkat akurasi yang tinggi dan tingkat kehilangan yang rendah, program breast cancer detection ini dapat digunakan sebagai alat yang berguna dalam membantu diagnosis dini kanker payudara. Dengan mendeteksi kanker payudara pada tahap awal, pasien dapat segera mendapatkan perawatan yang tepat, meningkatkan peluang kesembuhan, dan mengurangi dampak yang ditimbulkan oleh penyakit ini.\n",
        "\n",
        "Namun, perlu diingat bahwa hasil prediksi dari program ini masih memerlukan verifikasi lebih lanjut oleh tenaga medis yang berkualifikasi. Program ini sebaiknya digunakan sebagai alat pendukung dan bukan sebagai pengganti diagnosa dan perawatan medis yang profesional.\n",
        "\n",
        "Dengan demikian, program breast cancer detection dengan tingkat akurasi 94% hingga 96% dan tingkat kehilangan 9% hingga 18% memiliki potensi besar dalam membantu deteksi dini kanker payudara dan meningkatkan kesempatan penyembuhan pasien."
      ],
      "metadata": {
        "id": "ImIblt2B0JrH"
      }
    }
  ]
}